{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DreamJobber"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tech Edition**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Process**\n",
    "1. Clean text\n",
    "2. Bag of Words\n",
    "3. LDA model (Latent Dirichlet allocation)\n",
    "4. Fine tune LDA model\n",
    "5. Define Topics from LDA model\n",
    "6. Create df of document probabilities\n",
    "6. Nearest Neighbors Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import Necessary Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "import nltk\n",
    "from dreamjobber_web.recommend import input_user_scores, make_recommendation, collect_score_and_recommend, collect_feedback, show_to_user\n",
    "from functions import lemmatize_stem, preprocess, remove_brackets, remove_punctuation, remove_stop_words\n",
    "from lda import show_topics_sentences\n",
    "import pickle\n",
    "\n",
    "#lda model evaluation with coherence\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/admin/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.read_json('data/dice_jobs_1.json', lines=True)\n",
    "df_2 = pd.read_json('data/dice_jobs_2.json', lines=True)\n",
    "df_3 = pd.read_json('data/dice_jobs_3.json', lines=True)\n",
    "df_4 = pd.read_json('data/dice_jobs_4.json', lines=True)\n",
    "df_5 = pd.read_json('data/dice_jobs_5.json', lines=True)\n",
    "df_6 = pd.read_json('data/dice_jobs_6.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concat into one df\n",
    "df = pd.concat([df_1, df_2, df_3, df_4, df_5, df_6], ignore_index=True, sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_description</th>\n",
       "      <th>job_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>UI Lead/Architect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Web Application Architect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Senior DataStage Developer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Hadoop Administrator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>UX Visual Designer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  job_description                   job_title\n",
       "0             NaN           UI Lead/Architect\n",
       "1             NaN   Web Application Architect\n",
       "2             NaN  Senior DataStage Developer\n",
       "3             NaN        Hadoop Administrator\n",
       "4             NaN          UX Visual Designer"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "job_description    6524\n",
       "job_title          5484\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for missing values\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 27016 entries, 0 to 27015\n",
      "Data columns (total 2 columns):\n",
      "job_description    20492 non-null object\n",
      "job_title          21532 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 422.2+ KB\n"
     ]
    }
   ],
   "source": [
    "#looks like there are rows that have no job description\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop rows with no job descriptions\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 20492 entries, 9 to 27015\n",
      "Data columns (total 2 columns):\n",
      "job_description    20492 non-null object\n",
      "job_title          20492 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 480.3+ KB\n"
     ]
    }
   ],
   "source": [
    "#sanity check, looks good\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_description</th>\n",
       "      <th>job_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[2+ years of experience developing Java / J2EE...</td>\n",
       "      <td>Java Developer (Sign-On BONUS!)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[Passion for technology and learning, a natura...</td>\n",
       "      <td>iOS Developer - Mobile Rate: Open, Duration: 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[We enjoy approved IT vendor status with sever...</td>\n",
       "      <td>EUC Engineer, Rate-Open, Duration: 18 Months</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[We enjoy approved IT vendor status with sever...</td>\n",
       "      <td>Software Developer - RPG, Rate-Open, Duration:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[SME in Linux Operating system with Strong Vir...</td>\n",
       "      <td>Sr. Linux Consultant with Weblogic exp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      job_description  \\\n",
       "9   [2+ years of experience developing Java / J2EE...   \n",
       "10  [Passion for technology and learning, a natura...   \n",
       "17  [We enjoy approved IT vendor status with sever...   \n",
       "18  [We enjoy approved IT vendor status with sever...   \n",
       "19  [SME in Linux Operating system with Strong Vir...   \n",
       "\n",
       "                                            job_title  \n",
       "9                     Java Developer (Sign-On BONUS!)  \n",
       "10  iOS Developer - Mobile Rate: Open, Duration: 1...  \n",
       "17       EUC Engineer, Rate-Open, Duration: 18 Months  \n",
       "18  Software Developer - RPG, Rate-Open, Duration:...  \n",
       "19             Sr. Linux Consultant with Weblogic exp  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to remove brackets from job_description\n",
    "df['job_description'] = df['job_description'].map(remove_brackets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove '\\\\n' and replace with ','\n",
    "df['job_description'] = df['job_description'].map(lambda x: x.replace('\\\\n', ','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lowercase job_description text before applying stopwords\n",
    "df['job_description'] = df['job_description'].map(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lowercase job_title text before cleaning\n",
    "df['job_title'] = df['job_title'].map(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove punctuation from job_title\n",
    "df['job_title'] = df['job_title'].map(remove_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove stop words from job_title\n",
    "df['job_title'] = df['job_title'].map(remove_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 20492 entries, 9 to 27015\n",
      "Data columns (total 2 columns):\n",
      "job_description    20492 non-null object\n",
      "job_title          20492 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 480.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop any duplicates\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 18704 entries, 9 to 27015\n",
      "Data columns (total 2 columns):\n",
      "job_description    18704 non-null object\n",
      "job_title          18704 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 438.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reset the index\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_description</th>\n",
       "      <th>job_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1526</th>\n",
       "      <td>''</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2508</th>\n",
       "      <td>'robert half technology is looking for an expe...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13230</th>\n",
       "      <td>'someone who has spent 8-10 years in insurance...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13569</th>\n",
       "      <td>'my client is looking for sap fico in houston,...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14136</th>\n",
       "      <td>'share your resume on click here to apply', 'j...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14157</th>\n",
       "      <td>'role : fico with s4 hana.,location : manitowo...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15118</th>\n",
       "      <td>'hello all,', '', '', '', '', '', '', '', '', ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16508</th>\n",
       "      <td>'job description:', 'leidos is looking for a j...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         job_description job_title\n",
       "1526                                                  ''          \n",
       "2508   'robert half technology is looking for an expe...          \n",
       "13230  'someone who has spent 8-10 years in insurance...          \n",
       "13569  'my client is looking for sap fico in houston,...          \n",
       "14136  'share your resume on click here to apply', 'j...          \n",
       "14157  'role : fico with s4 hana.,location : manitowo...          \n",
       "15118  'hello all,', '', '', '', '', '', '', '', '', ...          \n",
       "16508  'job description:', 'leidos is looking for a j...          "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check to see if there are any job titles that have been removed via stopwords, I will want to remove these rows\n",
    "#because the job titles were not real job titles\n",
    "df.loc[df['job_title']=='']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(df.index[[1526, 2508, 13230, 13569, 14136, 14157, 15118, 16508]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_description</th>\n",
       "      <th>job_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [job_description, job_title]\n",
       "Index: []"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sanity check\n",
    "df.loc[df['job_title']=='']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_description</th>\n",
       "      <th>job_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'2+ years of experience developing java / j2ee...</td>\n",
       "      <td>java developer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'passion for technology and learning, a natura...</td>\n",
       "      <td>ios developer mobile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'we enjoy approved it vendor status with sever...</td>\n",
       "      <td>euc engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'we enjoy approved it vendor status with sever...</td>\n",
       "      <td>software developer rpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'sme in linux operating system with strong vir...</td>\n",
       "      <td>linux consultant with weblogic exp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     job_description  \\\n",
       "0  '2+ years of experience developing java / j2ee...   \n",
       "1  'passion for technology and learning, a natura...   \n",
       "2  'we enjoy approved it vendor status with sever...   \n",
       "3  'we enjoy approved it vendor status with sever...   \n",
       "4  'sme in linux operating system with strong vir...   \n",
       "\n",
       "                            job_title  \n",
       "0                      java developer  \n",
       "1                ios developer mobile  \n",
       "2                        euc engineer  \n",
       "3              software developer rpg  \n",
       "4  linux consultant with weblogic exp  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reset index one last time\n",
    "df = df.reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Tokenize\n",
    "2. Remove words with fewer than 2 characters\n",
    "3. Remove stop words\n",
    "4. Normalize words (Lemmatize and Stem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test the functions on one row of text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original text: \n",
      "[\"'demonstrates\", 'brand', 'passion,champions', 'and', 'embraces', 'change,makes', 'good', 'decisions,delivers', 'results,takes', 'action', 'with', 'integrity,communicates', \"effectively'\"]\n",
      "\n",
      "\n",
      " tokenized and lemmatized text: \n",
      "['demonstr', 'brand', 'passion', 'champion', 'embrac', 'chang', 'make', 'good', 'decis', 'deliv', 'result', 'take', 'action', 'integr', 'communic', 'effect']\n"
     ]
    }
   ],
   "source": [
    "text_sample = df[df.index == 13].values[0][0]\n",
    "\n",
    "print('original text: ')\n",
    "words = []\n",
    "for word in text_sample.split(' '):\n",
    "    words.append(word)\n",
    "print(words)\n",
    "print('\\n\\n tokenized and lemmatized text: ')\n",
    "print(preprocess(text_sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Apply cleaning functions to job_description**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#apply text cleaning function and display first 5 rows\n",
    "processed_text = df['job_description'].map(preprocess)\n",
    "processed_text[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I'll use bag of words to extract features from text for use in modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = gensim.corpora.Dictionary(processed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the length before I filter out the extremes\n",
    "len(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary.filter_extremes(no_below=25, no_above=0.5, keep_n=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check length after filtering out extremes\n",
    "len(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bow2doc: counts the number of occurrences of each distinct word, \n",
    "#converts the word to its integer word id and returns the result as a sparse vector\n",
    "\n",
    "bow2doc_corpus = [dictionary.doc2bow(text) for text in processed_text]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA model with Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.LdaMulticore(bow2doc_corpus, \n",
    "                                       num_topics=9, \n",
    "                                       id2word=dictionary, \n",
    "                                       passes=50, \n",
    "                                       workers=4,\n",
    "                                      chunksize=500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pickled LDA model results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle.dump(lda_model, open('dreamjobber_web/webapp/pickled_models/lda_model.pkl', 'wb'))\n",
    "pickled_lda = pickle.load(open('dreamjobber_web/webapp/pickled_models/lda_model.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, topic in pickled_lda.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#manually name topics\n",
    "col_names=['Analyst', 'Security', 'Leadership', 'Software/Web Dev', \n",
    "           'Cloud Computing', 'Computer Network', 'Database Admin', 'Computer Support', 'WebDev']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LDA model evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Coherence Score using c_v\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=processed_text, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Coherence Score using UMass\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=processed_text, dictionary=dictionary, coherence=\"u_mass\")\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##visualize the topics in order to better label \n",
    "#you may need to pip install pyLDAvis\n",
    "#!pip install pyLDAvis\n",
    "%matplotlib inline\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "vis = pyLDAvis.gensim.prepare(topic_model=lda_model, corpus=bow2doc_corpus, dictionary=dictionary)\n",
    "pyLDAvis.enable_notebook()\n",
    "pyLDAvis.display(vis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show topics and descriptions\n",
    "df_topic_sents_keywords = show_topics_sentences(ldamodel=pickled_lda, corpus=bow2doc_corpus, texts=df['job_description'])\n",
    "\n",
    "\n",
    "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
    "df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dominant_topic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create df for topic scores for each jobtitle**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get probabilities of a document belonging to each topic and append to list\n",
    "topic_vecs = []\n",
    "for i in range(len(bow2doc_corpus)):\n",
    "    top_topics = pickled_lda.get_document_topics(bow2doc_corpus[i], minimum_probability=0.0)\n",
    "    #i in range(amount of topics)\n",
    "    topic_vec = [top_topics[i][1] for i in range(9)]\n",
    "    topic_vecs.append(topic_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dataframe for topic scores\n",
    "df_topic_vecs = pd.DataFrame(topic_vecs)\n",
    "df_topic_vecs.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#name columns for dataframe\n",
    "\n",
    "col_names=['Analyst', 'Security', 'Leadership', 'Software/Web Dev', \n",
    "           'Cloud Computing', 'Computer Network', 'Database Admin', 'Computer Support', 'WebDev']\n",
    "\n",
    "\n",
    "\n",
    "df_topic_vecs.columns = col_names\n",
    "df_topic_vecs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#next step merge with original df of job titles and job descriptions\n",
    "#pickle the merged df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.merge(df, df_topic_vecs,left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle.dump(df_final, open('dreamjobber_web/webapp/pickled_models/df_final.pkl', 'wb'))\n",
    "pickled_df_final = pickle.load(open('dreamjobber_web/webapp/pickled_models/df_final.pkl', 'rb'))\n",
    "pickled_df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = pickled_df_final.drop(['job_description', 'job_title'], axis=1)\n",
    "jobs = pickled_df_final['job_title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle jobs for use in webapp\n",
    "#pickle.dump(jobs, open('dreamjobber_web/webapp/pickled_models/jobs.pkl', 'wb'))\n",
    "jobs = pickle.load(open('dreamjobber_web/webapp/pickled_models/jobs.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nearest_neighbor = NearestNeighbors(n_neighbors=50)\n",
    "nearest_neighbor.fit(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle.dump(nearest_neighbor, open('dreamjobber_web/webapp/pickled_models/nn_model.pkl', 'wb'))\n",
    "nearest_neighbor = pickle.load(open('dreamjobber_web/webapp/pickled_models/nn_model.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make Recommendations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scale of 0-10.\n",
      "    0 is Do NOT agree and 10 is agree\n",
      "Agree or Disagree: I am/I like Analyst: 1\n",
      "Agree or Disagree: I am/I like Security: 2\n",
      "Agree or Disagree: I am/I like Leadership: 3\n",
      "Agree or Disagree: I am/I like Software/Web Dev: 4\n",
      "Agree or Disagree: I am/I like Cloud Computing: 5\n",
      "Agree or Disagree: I am/I like Computer Network: 6\n",
      "Agree or Disagree: I am/I like Database Admin: 7\n",
      "Agree or Disagree: I am/I like Computer Support: 8\n",
      "Agree or Disagree: I am/I like WebDev: 9\n",
      "\n",
      "\n",
      "['1. firmware engineer iot engineer', '2. media buyer planner', '3. academic instructional designer', '4. digital content writer', '5. marketing manager product developer', '6. studio artist', '7. data analyst', '8. business system analyst with netsuite consultant', '9. artist rigger', '10. tech artist']\n",
      "How did you like your recommendations? bad, okay, or goodbad\n"
     ]
    }
   ],
   "source": [
    "show_to_user(nearest_neighbor, jobs)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
