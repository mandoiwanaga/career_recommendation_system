{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DreamJobber"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tech Edition**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Process**\n",
    "1. Clean text\n",
    "2. Bag of Words\n",
    "3. LDA model (Latent Dirichlet allocation)\n",
    "4. Fine tune LDA model\n",
    "5. Define Topics from LDA model\n",
    "6. Create df of document probabilities\n",
    "6. Classification model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import Necessary Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "import nltk\n",
    "from functions import *\n",
    "import pickle\n",
    "\n",
    "#lda model evaluatoin with coherence\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/admin/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.read_json('data/dice_jobs_1.json', lines=True)\n",
    "df_2 = pd.read_json('data/dice_jobs_2.json', lines=True)\n",
    "df_3 = pd.read_json('data/dice_jobs_3.json', lines=True)\n",
    "df_4 = pd.read_json('data/dice_jobs_4.json', lines=True)\n",
    "df_5 = pd.read_json('data/dice_jobs_5.json', lines=True)\n",
    "df_6 = pd.read_json('data/dice_jobs_6.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concat into one df\n",
    "df = pd.concat([df_1, df_2, df_3, df_4, df_5, df_6], ignore_index=True, sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_description</th>\n",
       "      <th>job_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>UI Lead/Architect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Web Application Architect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Senior DataStage Developer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Hadoop Administrator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>UX Visual Designer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  job_description                   job_title\n",
       "0             NaN           UI Lead/Architect\n",
       "1             NaN   Web Application Architect\n",
       "2             NaN  Senior DataStage Developer\n",
       "3             NaN        Hadoop Administrator\n",
       "4             NaN          UX Visual Designer"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "job_description    6524\n",
       "job_title          5484\n",
       "dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for missing values\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 27016 entries, 0 to 27015\n",
      "Data columns (total 2 columns):\n",
      "job_description    20492 non-null object\n",
      "job_title          21532 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 422.2+ KB\n"
     ]
    }
   ],
   "source": [
    "#looks like there are rows that have no job description\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop rows with no job descriptions\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 20492 entries, 9 to 27015\n",
      "Data columns (total 2 columns):\n",
      "job_description    20492 non-null object\n",
      "job_title          20492 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 480.3+ KB\n"
     ]
    }
   ],
   "source": [
    "#sanity check, looks good\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_description</th>\n",
       "      <th>job_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[2+ years of experience developing Java / J2EE...</td>\n",
       "      <td>Java Developer (Sign-On BONUS!)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[Passion for technology and learning, a natura...</td>\n",
       "      <td>iOS Developer - Mobile Rate: Open, Duration: 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[We enjoy approved IT vendor status with sever...</td>\n",
       "      <td>EUC Engineer, Rate-Open, Duration: 18 Months</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[We enjoy approved IT vendor status with sever...</td>\n",
       "      <td>Software Developer - RPG, Rate-Open, Duration:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[SME in Linux Operating system with Strong Vir...</td>\n",
       "      <td>Sr. Linux Consultant with Weblogic exp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      job_description  \\\n",
       "9   [2+ years of experience developing Java / J2EE...   \n",
       "10  [Passion for technology and learning, a natura...   \n",
       "17  [We enjoy approved IT vendor status with sever...   \n",
       "18  [We enjoy approved IT vendor status with sever...   \n",
       "19  [SME in Linux Operating system with Strong Vir...   \n",
       "\n",
       "                                            job_title  \n",
       "9                     Java Developer (Sign-On BONUS!)  \n",
       "10  iOS Developer - Mobile Rate: Open, Duration: 1...  \n",
       "17       EUC Engineer, Rate-Open, Duration: 18 Months  \n",
       "18  Software Developer - RPG, Rate-Open, Duration:...  \n",
       "19             Sr. Linux Consultant with Weblogic exp  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to remove brackets from job_description\n",
    "df['job_description'] = df['job_description'].map(remove_brackets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove '\\\\n' and replace with ','\n",
    "df['job_description'] = df['job_description'].map(lambda x: x.replace('\\\\n', ','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lowercase text before applying stopwords\n",
    "df['job_description'] = df['job_description'].map(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_description</th>\n",
       "      <th>job_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>'2+ years of experience developing java / j2ee...</td>\n",
       "      <td>Java Developer (Sign-On BONUS!)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>'passion for technology and learning, a natura...</td>\n",
       "      <td>iOS Developer - Mobile Rate: Open, Duration: 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>'we enjoy approved it vendor status with sever...</td>\n",
       "      <td>EUC Engineer, Rate-Open, Duration: 18 Months</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>'we enjoy approved it vendor status with sever...</td>\n",
       "      <td>Software Developer - RPG, Rate-Open, Duration:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>'sme in linux operating system with strong vir...</td>\n",
       "      <td>Sr. Linux Consultant with Weblogic exp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      job_description  \\\n",
       "9   '2+ years of experience developing java / j2ee...   \n",
       "10  'passion for technology and learning, a natura...   \n",
       "17  'we enjoy approved it vendor status with sever...   \n",
       "18  'we enjoy approved it vendor status with sever...   \n",
       "19  'sme in linux operating system with strong vir...   \n",
       "\n",
       "                                            job_title  \n",
       "9                     Java Developer (Sign-On BONUS!)  \n",
       "10  iOS Developer - Mobile Rate: Open, Duration: 1...  \n",
       "17       EUC Engineer, Rate-Open, Duration: 18 Months  \n",
       "18  Software Developer - RPG, Rate-Open, Duration:...  \n",
       "19             Sr. Linux Consultant with Weblogic exp  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lowercase job_title text before cleaning\n",
    "df['job_title'] = df['job_title'].map(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def remove_stop_words(list1):\n",
    " #   result = []\n",
    "  #  for word in list1:\n",
    "   #     if word not in jobtitle_stopwords:\n",
    "    #        result.append(word)\n",
    "    #return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['job_title'] = df['job_title'].apply(remove_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_description</th>\n",
       "      <th>job_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>'2+ years of experience developing java / j2ee...</td>\n",
       "      <td>java developer (sign-on bonus!)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>'passion for technology and learning, a natura...</td>\n",
       "      <td>ios developer - mobile rate: open, duration: 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>'we enjoy approved it vendor status with sever...</td>\n",
       "      <td>euc engineer, rate-open, duration: 18 months</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>'we enjoy approved it vendor status with sever...</td>\n",
       "      <td>software developer - rpg, rate-open, duration:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>'sme in linux operating system with strong vir...</td>\n",
       "      <td>sr. linux consultant with weblogic exp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      job_description  \\\n",
       "9   '2+ years of experience developing java / j2ee...   \n",
       "10  'passion for technology and learning, a natura...   \n",
       "17  'we enjoy approved it vendor status with sever...   \n",
       "18  'we enjoy approved it vendor status with sever...   \n",
       "19  'sme in linux operating system with strong vir...   \n",
       "\n",
       "                                            job_title  \n",
       "9                     java developer (sign-on bonus!)  \n",
       "10  ios developer - mobile rate: open, duration: 1...  \n",
       "17       euc engineer, rate-open, duration: 18 months  \n",
       "18  software developer - rpg, rate-open, duration:...  \n",
       "19             sr. linux consultant with weblogic exp  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Tokenize\n",
    "2. Remove words with fewer than 3 characters\n",
    "3. Remove stop words\n",
    "4. Normalize words (Lemmatize and Stem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test the functions on one row of text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original text: \n",
      "[\"'our\", 'client,', 'a', 'top', 'national', 'optometry', 'retailer', 'is', 'currently', 'looking', 'for', 'a', 'hris', 'analyst', 'to', 'help', 'command', 'and', 'support', 'their', 'current', 'human', 'resource', 'system', 'functions.', 'our', 'client', 'heavily', 'works', 'in', 'a', 'ceridian', 'dayforce', 'environment', 'is', 'looking', 'for', 'an', 'experience', 'resource', 'to', 'support', 'their', 'hr', 'team.,role', \"summary:',\", \"'the\", 'human', 'resources', 'information', 'systems', '(hris)', 'analyst', 'is', 'part', 'of', 'the', 'overall', 'hr', 'team', 'and', 'is', 'a', 'key', 'partner', 'and', 'liaison', 'to', 'all', 'centers', 'of', 'excellence.', 'the', 'hris', 'analyst', 'is', 'not', 'only', 'responsible', 'for', 'comprehensive', 'and', 'strategic', 'hr', 'systems', 'administration,', 'but', 'also', 'acts', 'as', 'a', 'business', 'partner', 'to', 'other', 'members', 'of', 'the', 'team,', 'ensuring', 'that', 'all', 'hr', 'centers', 'of', 'excellence', 'have', 'the', 'tools', 'and', 'access', 'necessary', 'to', 'gain', 'hris', 'data', 'to', 'help', 'run', 'the', 'business.', 'representing', 'our', 'client', 's', 'brand,', 'the', 'successful', 'candidate', 'is', 'well-versed', 'in', 'hris', 'best', 'practices,', 'is', 'proficient', 'in', 'ceridian', 'dayforce,', 'is', 'client-focused', 'and', 'communicative,', 'is', 'well', 'organized,', 'and', 'is', 'efficient', 'and', 'effective', 'in', 'their', 'day-to-day', 'routine.', 'the', 'hris', 'analyst', 'is', 'sensitive', 'to', 'stakeholders', 'needs', 'while', 'adding', 'value', 'to', 'the', 'business', 'through', 'impactful', 'and', 'meaningful', 'partnership', 'through', 'hr', 'data.', 'this', 'role', 'works', 'closely', 'and', 'collaborates', 'with', 'the', 'centers', 'of', 'excellence', '(business', 'operations,', 'talent', 'acquisitions,', 'contract', 'services,', 'learning', '&', 'development,', 'compliance,', 'and', 'benefits)', 'to', 'ensure', 'the', 'one', 'team', 'approach,', 'the', 'needs', 'of', 'the', 'business', 'and', 'our', 'patients', 'are', 'met.', 'to', 'be', 'successful', 'in', 'this', 'role,', 'you', 'are', 'a', 'both', 'a', 'compassionate', 'and', 'driven', 'leader', 'who', 'works', 'well', 'under', 'pressure', 'and', 'tight', 'deadlines,', 'and', 'a', 'collaborative', 'partner', 'with', 'the', 'ability', 'to', 'work', 'seamlessly', 'with', 'the', 'business', 'and', 'works', 'with', 'little', 'to', 'no', 'supervision.,essential', 'duties', 'and', 'responsibilities:,system', 'maintenance', '(5%', 'of', 'time):', 'assist', 'in', 'the', 'review,', 'testing', 'and', 'implementation', 'of', 'hris', 'upgrades', 'or', 'patches.', 'collaborate', 'with', 'functional', 'and', 'technical', 'staff', 'to', 'coordinate', 'application', 'of', 'upgrade', 'or', 'fix.', 'maintain', 'hris', 'tables.', 'document', 'process', 'and', 'results.,production', 'support', '(20%', 'of', 'time):', 'provide', 'support', 'for', 'hris,', 'including', 'researching', 'and', 'resolving', 'hris', 'problems,', 'unexpected', 'results', 'or', 'process', 'flaws;', 'performing', 'scheduled', 'activities;', 'recommending', 'solutions', 'or', 'alternate', 'methods', 'to', 'meet', 'requirements.,projects/process', 'improvement', '(55%', 'of', 'time):', 'recommend', 'process/customer', 'service', 'improvements,', 'innovative', 'solutions,', 'policy', 'changes', 'and/or', 'major', 'variations', 'from', 'established', 'policy', 'that', 'must', 'be', 'approved', 'by', 'appropriate', 'leadership', 'prior', 'to', 'implementation.', 'serve', 'as', 'a', 'key', 'liaison', 'with', 'third', 'parties', 'and', 'other', 'stakeholders', '(e.g.', 'payroll).', 'use', 'project', 'management', 'skills', 'in', 'managing', 'projects.', 'may', 'provide', 'overall', 'project', 'management', 'for', 'a', 'given', 'hr', 'initiative.,reports/queries', '(10%', 'of', 'time):', 'write,', 'maintain', 'and', 'support', 'a', 'variety', 'of', 'reports', 'or', 'queries', 'using', 'appropriate', 'reporting', 'tools.', 'assist', 'in', 'development', 'of', 'standard', 'reports', 'for', 'ongoing', 'customer', 'needs.', 'help', 'maintain', 'data', 'integrity', 'in', 'systems', 'by', 'running', 'queries', 'and', 'analyzing', 'data.,training', '(5%', 'of', 'time):', 'develop', 'user', 'procedures,', 'guidelines', 'and', 'documentation.', 'train', 'clients', 'on', 'new', 'processes/functionality.', 'train', 'new', 'system', 'users.,individual', 'development', '(5%', 'of', 'time):', 'maintain', 'awareness', 'of', 'current', 'trends', 'in', 'hris', 'with', 'a', 'focus', 'on', 'product', 'and', 'service', 'development,', 'delivery', 'and', 'support,', 'and', 'applying', 'key', 'technologies.', 'examine', 'trends', 'in', 'information', 'systems', 'training,', 'materials', 'and', 'techniques.', 'through', 'classes,', 'reading,', 'or', 'other', 'mechanisms,', 'continuously', 'increase', 'both', 'hr', 'knowledge', 'and', 'hris', 'application/tools', 'knowledge.', 'seek', 'certification', 'in', 'hris', 'application', 'as', 'appropriate.', 'participate', 'in', 'user', 'group', 'meetings/conferences.,partner', 'with', 'all', 'levels', 'of', 'leaders', 'to', 'ensure', 'overall', 'business', 'data', 'needs', 'are', 'being', 'met.,prepares', 'progress', 'reports', 'to', 'inform', 'management', 'of', 'project', 'status', 'and', 'deviation', 'from', 'goals.,performs', 'other', 'duties', 'and', 'projects', 'as', 'assigned.,work', 'experience:,5+', 'years', 'with', 'hris', 'data', 'analytics,experience', 'with', 'ceridian', 'dayforce', 'is', 'preferred,3+', 'years', 'closely', 'collaborating', 'with', 'leader', 'business', 'stakeholders', 'to', 'develop', 'best', 'practices,2-3', 'years', 'working', 'with', 'limited', 'to', 'no', 'supervision,experience', 'meeting', 'timelines', 'and', 'creative', 'problem', 'solving,demonstrated', 'project', 'management', 'skills,working', 'knowledge', 'of', 'microsoft', 'products,3+', 'year', 'experience', 'overall', 'working', 'with', 'hr', 'business', 'applications', 'and', 'systems', 'in', 'a', 'support', 'role', 'with', 'experience', 'documenting', 'software', 'user', 'needs,', 'maintaining', 'business', 'application', 'configurations,', 'and', 'the', 'use', 'of', 'application', 'reporting', 'tools.', '(from', 'it', 'application', 'analyst', 'role),education', 'requirements:,ba/bs', 'from', 'an', 'accredited', \"university',\", \"'id:\", \"19-00656'\"]\n",
      "\n",
      "\n",
      " tokenized and lemmatized text: \n",
      "['optometri', 'retail', 'current', 'look', 'hris', 'analyst', 'help', 'command', 'support', 'current', 'human', 'resourc', 'function', 'heavili', 'work', 'ceridian', 'dayforc', 'environ', 'look', 'resourc', 'support', 'team', 'role', 'summari', 'human', 'resourc', 'inform', 'system', 'hris', 'analyst', 'overal', 'team', 'partner', 'liaison', 'center', 'excel', 'hris', 'analyst', 'respons', 'comprehens', 'strateg', 'system', 'administr', 'act', 'busi', 'partner', 'member', 'team', 'ensur', 'center', 'excel', 'tool', 'access', 'necessari', 'gain', 'hris', 'data', 'help', 'busi', 'repres', 'brand', 'success', 'vers', 'hris', 'best', 'practic', 'profici', 'ceridian', 'dayforc', 'focus', 'communic', 'organ', 'effici', 'effect', 'routin', 'hris', 'analyst', 'sensit', 'stakehold', 'need', 'add', 'valu', 'busi', 'impact', 'meaning', 'partnership', 'data', 'role', 'work', 'close', 'collabor', 'center', 'excel', 'busi', 'oper', 'talent', 'acquisit', 'servic', 'learn', 'develop', 'complianc', 'ensur', 'team', 'approach', 'need', 'busi', 'patient', 'success', 'role', 'compassion', 'drive', 'leader', 'work', 'pressur', 'tight', 'deadlin', 'collabor', 'partner', 'abil', 'work', 'seamless', 'busi', 'work', 'littl', 'supervis', 'essenti', 'duti', 'mainten', 'time', 'assist', 'review', 'test', 'implement', 'hris', 'upgrad', 'patch', 'collabor', 'function', 'technic', 'coordin', 'upgrad', 'maintain', 'hris', 'tabl', 'document', 'process', 'result', 'product', 'support', 'time', 'provid', 'support', 'hris', 'includ', 'research', 'resolv', 'hris', 'problem', 'unexpect', 'result', 'process', 'flaw', 'perform', 'schedul', 'activ', 'recommend', 'solut', 'altern', 'method', 'meet', 'requir', 'project', 'process', 'improv', 'time', 'recommend', 'process', 'custom', 'servic', 'improv', 'innov', 'solut', 'polici', 'chang', 'major', 'variat', 'establish', 'polici', 'approv', 'appropri', 'leadership', 'prior', 'implement', 'serv', 'liaison', 'parti', 'stakehold', 'project', 'manag', 'manag', 'project', 'provid', 'overal', 'project', 'manag', 'give', 'initi', 'report', 'queri', 'time', 'write', 'maintain', 'support', 'varieti', 'report', 'queri', 'appropri', 'report', 'tool', 'assist', 'develop', 'standard', 'report', 'ongo', 'custom', 'need', 'help', 'maintain', 'data', 'integr', 'system', 'run', 'queri', 'analyz', 'data', 'train', 'time', 'develop', 'user', 'procedur', 'guidelin', 'document', 'train', 'client', 'process', 'function', 'train', 'user', 'individu', 'develop', 'time', 'maintain', 'awar', 'current', 'trend', 'hris', 'focus', 'product', 'servic', 'develop', 'deliveri', 'support', 'appli', 'technolog', 'examin', 'trend', 'inform', 'system', 'train', 'materi', 'techniqu', 'class', 'read', 'mechan', 'continu', 'increas', 'knowledg', 'hris', 'tool', 'knowledg', 'seek', 'hris', 'appropri', 'particip', 'user', 'group', 'meet', 'confer', 'partner', 'level', 'leader', 'ensur', 'overal', 'busi', 'data', 'need', 'prepar', 'progress', 'report', 'inform', 'manag', 'project', 'status', 'deviat', 'goal', 'perform', 'duti', 'project', 'assign', 'work', 'year', 'hris', 'data', 'analyt', 'ceridian', 'dayforc', 'year', 'close', 'collabor', 'leader', 'busi', 'stakehold', 'develop', 'best', 'practic', 'year', 'work', 'limit', 'supervis', 'meet', 'timelin', 'creativ', 'problem', 'solv', 'demonstr', 'project', 'manag', 'work', 'knowledg', 'microsoft', 'product', 'overal', 'work', 'busi', 'applic', 'system', 'support', 'role', 'document', 'softwar', 'user', 'need', 'maintain', 'busi', 'configur', 'report', 'tool', 'analyst', 'role', 'requir', 'univers']\n"
     ]
    }
   ],
   "source": [
    "text_sample = df[df.index == 14677].values[0][0]\n",
    "\n",
    "print('original text: ')\n",
    "words = []\n",
    "for word in text_sample.split(' '):\n",
    "    words.append(word)\n",
    "print(words)\n",
    "print('\\n\\n tokenized and lemmatized text: ')\n",
    "print(preprocess(text_sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Apply functions to job_description**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9                         [year, develop, java, applic]\n",
       "10    [passion, technolog, learn, natur, curios, lov...\n",
       "17    [enjoy, approv, vendor, status, lead, compani,...\n",
       "18    [enjoy, approv, vendor, status, lead, compani,...\n",
       "19    [linux, oper, strong, virtual, knowledg, vmwar...\n",
       "Name: job_description, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#apply function and display first 5 rows\n",
    "processed_text = df['job_description'].map(preprocess)\n",
    "processed_text[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I'll use bag of words to extract features from text for use in modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = gensim.corpora.Dictionary(processed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21777"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the length before I filter out the extremes\n",
    "len(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4445"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check length after filtering out extremes\n",
    "len(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bow2doc: counts the number of occurrences of each distinct word, \n",
    "#converts the word to its integer word id and returns the result as a sparse vector\n",
    "\n",
    "bow2doc_corpus = [dictionary.doc2bow(text) for text in processed_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##let's take a look\n",
    "#bow_doc_5000 = bow2doc_corpus[5000]\n",
    "\n",
    "#for i in range(len(bow_doc_5000)):\n",
    " #   print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_doc_5000[i][0], \n",
    "  #                                                   dictionary[bow_doc_5000[i][0]], \n",
    "   #                                                  bow_doc_5000[i][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find optimal number of topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_list, coherence_values = compute_coherence_values(dictionary=dictionary, corpus=bow2doc_corpus,\n",
    " #                                                       texts=processed_text, start=5, limit=40, step=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import matplotlib.pyplot as plt\n",
    "#limit=40; start=5; step=5;\n",
    "#x = range(start, limit, step)\n",
    "#plt.plot(x, coherence_values)\n",
    "#plt.xlabel(\"Number of Topics\")\n",
    "#plt.ylabel(\"Coherence score\")\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA model with Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.LdaMulticore(bow2doc_corpus, \n",
    "                                       num_topics=9, \n",
    "                                       id2word=dictionary, \n",
    "                                       passes=100, \n",
    "                                       workers=4,\n",
    "                                      chunksize=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.036*\"project\" + 0.028*\"busi\" + 0.014*\"process\" + 0.013*\"abil\" + 0.012*\"technic\" + 0.011*\"requir\" + 0.011*\"plan\" + 0.010*\"solut\" + 0.010*\"product\" + 0.009*\"provid\"\n",
      "Topic: 1 \n",
      "Words: 0.023*\"compani\" + 0.015*\"posit\" + 0.015*\"look\" + 0.013*\"solut\" + 0.012*\"client\" + 0.012*\"help\" + 0.010*\"industri\" + 0.009*\"need\" + 0.009*\"world\" + 0.008*\"grow\"\n",
      "Topic: 2 \n",
      "Words: 0.048*\"secur\" + 0.034*\"network\" + 0.021*\"system\" + 0.014*\"administr\" + 0.014*\"oper\" + 0.014*\"server\" + 0.014*\"infrastructur\" + 0.014*\"configur\" + 0.012*\"engin\" + 0.010*\"implement\"\n",
      "Topic: 3 \n",
      "Words: 0.067*\"test\" + 0.019*\"user\" + 0.017*\"softwar\" + 0.016*\"autom\" + 0.015*\"requir\" + 0.014*\"applic\" + 0.013*\"integr\" + 0.012*\"document\" + 0.011*\"function\" + 0.010*\"salesforc\"\n",
      "Topic: 4 \n",
      "Words: 0.021*\"status\" + 0.018*\"applic\" + 0.018*\"protect\" + 0.017*\"receiv\" + 0.014*\"origin\" + 0.013*\"qualifi\" + 0.013*\"ident\" + 0.013*\"posit\" + 0.012*\"elig\" + 0.012*\"busi\"\n",
      "Topic: 5 \n",
      "Words: 0.026*\"softwar\" + 0.022*\"java\" + 0.021*\"engin\" + 0.015*\"cloud\" + 0.014*\"architectur\" + 0.013*\"applic\" + 0.013*\"build\" + 0.012*\"framework\" + 0.011*\"strong\" + 0.011*\"code\"\n",
      "Topic: 6 \n",
      "Words: 0.014*\"abil\" + 0.013*\"technic\" + 0.012*\"system\" + 0.012*\"custom\" + 0.012*\"provid\" + 0.011*\"problem\" + 0.011*\"issu\" + 0.011*\"softwar\" + 0.010*\"engin\" + 0.010*\"oper\"\n",
      "Topic: 7 \n",
      "Words: 0.134*\"data\" + 0.023*\"databas\" + 0.022*\"analyst\" + 0.019*\"function\" + 0.019*\"model\" + 0.018*\"architect\" + 0.017*\"oracl\" + 0.016*\"system\" + 0.015*\"analyt\" + 0.014*\"report\"\n",
      "Topic: 8 \n",
      "Words: 0.036*\"market\" + 0.023*\"digit\" + 0.018*\"product\" + 0.015*\"sale\" + 0.014*\"content\" + 0.013*\"creativ\" + 0.009*\"campaign\" + 0.009*\"custom\" + 0.009*\"media\" + 0.008*\"strategi\"\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pickled LDA model results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle.dump(lda_model, open('pickled_models/lda_model.pkl', 'wb'))\n",
    "pickled_lda = pickle.load(open('pickled_models/lda_model.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, topic in pickled_lda.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Coherence Score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Coherence Score using c_v\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=processed_text, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Coherence Score using UMass\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=processed_text, dictionary=dictionary, coherence=\"u_mass\")\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pyLDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##visualize the topics in order to better label \n",
    "%matplotlib inline\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "vis = pyLDAvis.gensim.prepare(topic_model=lda_model, corpus=bow2doc_corpus, dictionary=dictionary)\n",
    "pyLDAvis.enable_notebook()\n",
    "pyLDAvis.display(vis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_topics_sentences(ldamodel, corpus, texts):\n",
    "    # Init output\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "\n",
    "    # Get main topic in each document\n",
    "    for i, row in enumerate(ldamodel[corpus]):\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "\n",
    "    # Add original text to the end of the output\n",
    "    contents = pd.Series(texts)\n",
    "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
    "    return(sent_topics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topic_sents_keywords = format_topics_sentences(ldamodel=lda_model, corpus=bow2doc_corpus, texts=df['job_description'])\n",
    "\n",
    "# Format\n",
    "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
    "df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create df for topic scores for each jobtitle**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_vecs = []\n",
    "for i in range(len(bow2doc_corpus)):\n",
    "    top_topics = pickled_lda.get_document_topics(bow2doc_corpus[i], minimum_probability=0.0)\n",
    "    #i in range(amount of topics)\n",
    "    topic_vec = [top_topics[i][1] for i in range(9)]\n",
    "    topic_vecs.append(topic_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topic_vecs = pd.DataFrame(topic_vecs)\n",
    "df_topic_vecs.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#name columns for df\n",
    "col_names=['Database Admin', 'Computer Network', 'Software/App Dev', 'Security', \n",
    "           'Analyst', 'Leadership', 'Computer Support', \n",
    "           'WebDev', 'Cloud Computing']\n",
    "df_topic_vecs.columns = col_names\n",
    "df_topic_vecs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#next step merge with original df of job titles and job descriptions\n",
    "#pickle the merged df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.merge(df, df_topic_vecs,left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle.dump(df_final, open('pickled_models/df_final.pkl', 'wb'))\n",
    "pickled_df_final = pickle.load(open('pickled_models/df_final.pkl', 'rb'))\n",
    "pickled_df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = pickled_df_final.drop(['job_description', 'job_title'], axis=1)\n",
    "jobs = pickled_df_final['job_title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nearest_neighbor = NearestNeighbors(n_neighbors=50, metric='cosine')\n",
    "nearest_neighbor.fit(topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collect_score_and_recommend(nearest_neighbor, jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#next-steps\n",
    "#1.more stopwords for descriptions(countries, cities, company names)\n",
    "#2.find best topic separation and pickle\n",
    "#3.stop words for job_titles\n",
    "#4.find a way a to group similar job titles\n",
    "#5.recommendations return unique list of top 10\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
