{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DreamJobber"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tech Edition**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Process**\n",
    "1. Clean text\n",
    "2. Bag of Words\n",
    "3. LDA model (Latent Dirichlet allocation)\n",
    "4. Fine tune LDA model\n",
    "5. Define Topics from LDA model\n",
    "6. Create df of document probabilities\n",
    "6. Classification model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import Necessary Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "import nltk\n",
    "from functions import *\n",
    "import pickle\n",
    "\n",
    "#lda model evaluatoin with coherence\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/admin/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.read_json('data/dice_jobs_1.json', lines=True)\n",
    "df_2 = pd.read_json('data/dice_jobs_2.json', lines=True)\n",
    "df_3 = pd.read_json('data/dice_jobs_3.json', lines=True)\n",
    "df_4 = pd.read_json('data/dice_jobs_4.json', lines=True)\n",
    "df_5 = pd.read_json('data/dice_jobs_5.json', lines=True)\n",
    "df_6 = pd.read_json('data/dice_jobs_6.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concat into one df\n",
    "df = pd.concat([df_1, df_2, df_3, df_4, df_5, df_6], ignore_index=True, sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_description</th>\n",
       "      <th>job_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>UI Lead/Architect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Web Application Architect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Senior DataStage Developer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Hadoop Administrator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>UX Visual Designer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  job_description                   job_title\n",
       "0             NaN           UI Lead/Architect\n",
       "1             NaN   Web Application Architect\n",
       "2             NaN  Senior DataStage Developer\n",
       "3             NaN        Hadoop Administrator\n",
       "4             NaN          UX Visual Designer"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "job_description    6524\n",
       "job_title          5484\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for missing values\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 27016 entries, 0 to 27015\n",
      "Data columns (total 2 columns):\n",
      "job_description    20492 non-null object\n",
      "job_title          21532 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 422.2+ KB\n"
     ]
    }
   ],
   "source": [
    "#looks like there are rows that have no job description\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop rows with no job descriptions\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 20492 entries, 9 to 27015\n",
      "Data columns (total 2 columns):\n",
      "job_description    20492 non-null object\n",
      "job_title          20492 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 480.3+ KB\n"
     ]
    }
   ],
   "source": [
    "#sanity check, looks good\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_description</th>\n",
       "      <th>job_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[2+ years of experience developing Java / J2EE...</td>\n",
       "      <td>Java Developer (Sign-On BONUS!)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[Passion for technology and learning, a natura...</td>\n",
       "      <td>iOS Developer - Mobile Rate: Open, Duration: 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[We enjoy approved IT vendor status with sever...</td>\n",
       "      <td>EUC Engineer, Rate-Open, Duration: 18 Months</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[We enjoy approved IT vendor status with sever...</td>\n",
       "      <td>Software Developer - RPG, Rate-Open, Duration:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[SME in Linux Operating system with Strong Vir...</td>\n",
       "      <td>Sr. Linux Consultant with Weblogic exp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      job_description  \\\n",
       "9   [2+ years of experience developing Java / J2EE...   \n",
       "10  [Passion for technology and learning, a natura...   \n",
       "17  [We enjoy approved IT vendor status with sever...   \n",
       "18  [We enjoy approved IT vendor status with sever...   \n",
       "19  [SME in Linux Operating system with Strong Vir...   \n",
       "\n",
       "                                            job_title  \n",
       "9                     Java Developer (Sign-On BONUS!)  \n",
       "10  iOS Developer - Mobile Rate: Open, Duration: 1...  \n",
       "17       EUC Engineer, Rate-Open, Duration: 18 Months  \n",
       "18  Software Developer - RPG, Rate-Open, Duration:...  \n",
       "19             Sr. Linux Consultant with Weblogic exp  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to remove brackets from job_description\n",
    "df['job_description'] = df['job_description'].map(remove_brackets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove '\\\\n' and replace with ','\n",
    "df['job_description'] = df['job_description'].map(lambda x: x.replace('\\\\n', ','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lowercase text before applying stopwords\n",
    "df['job_description'] = df['job_description'].map(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lowercase job_title text before cleaning\n",
    "df['job_title'] = df['job_title'].map(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Return first title from job_titles\n",
    "df['job_title'] = df['job_title'].map(get_first_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def remove_stop_words(text):\n",
    "    \n",
    " #   \"\"\"Remove stopwords from job titles\"\"\"\n",
    "    \n",
    "  #  jobtitle_stopwords = ['bonus', \n",
    "   #                       'duration',\n",
    "    #                      'month',\n",
    "     #                     'open',\n",
    "      #                    'rate',\n",
    "       #                   'sign-on',\n",
    "        #                  'year']\n",
    "    \n",
    "    #result = []\n",
    "    \n",
    "    #for word in text:\n",
    "    \n",
    "     #   if word not in jobtitle_stopwords:\n",
    "      #      result.append(text)\n",
    "    #return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove stop words from job titles\n",
    "#df['job_title'] = df['job_title'].map(remove_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_description</th>\n",
       "      <th>job_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'2+ years of experience developing java / j2ee...</td>\n",
       "      <td>java developer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'passion for technology and learning, a natura...</td>\n",
       "      <td>ios developer - mobile rate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'we enjoy approved it vendor status with sever...</td>\n",
       "      <td>euc engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'we enjoy approved it vendor status with sever...</td>\n",
       "      <td>software developer - rpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'sme in linux operating system with strong vir...</td>\n",
       "      <td>sr. linux consultant with weblogic exp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     job_description  \\\n",
       "0  '2+ years of experience developing java / j2ee...   \n",
       "1  'passion for technology and learning, a natura...   \n",
       "2  'we enjoy approved it vendor status with sever...   \n",
       "3  'we enjoy approved it vendor status with sever...   \n",
       "4  'sme in linux operating system with strong vir...   \n",
       "\n",
       "                                job_title  \n",
       "0                          java developer  \n",
       "1             ios developer - mobile rate  \n",
       "2                            euc engineer  \n",
       "3                software developer - rpg  \n",
       "4  sr. linux consultant with weblogic exp  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20492 entries, 0 to 20491\n",
      "Data columns (total 2 columns):\n",
      "job_description    20492 non-null object\n",
      "job_title          20492 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 320.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 18709 entries, 0 to 20491\n",
      "Data columns (total 2 columns):\n",
      "job_description    18709 non-null object\n",
      "job_title          18709 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 438.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Tokenize\n",
    "2. Remove words with fewer than 3 characters\n",
    "3. Remove stop words\n",
    "4. Normalize words (Lemmatize and Stem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test the functions on one row of text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original text: \n",
      "[\"'we\", 'enjoy', 'approved', 'it', 'vendor', 'status', 'with', 'several', 'leading', 'companies', 'in', 'the', 'pacific', 'northwest', 'and', 'continually', 'grow', 'our', 'list', 'of', 'approved', 'vendor', 'status', 'with', 'additional', \"companies.',\", \"'we\", 'are', 'an', 'ethical', 'company', 'with', 'integrity', 'and', 'a', 'dedication', 'to', 'delivering', 'high', 'results', 'for', 'our', \"clients.',\", \"'we\", 'are', 'fair', 'and', 'honest', 'in', 'all', 'of', 'our', 'business', 'dealings', 'with', 'our', 'consultants', 'and', \"clients',\", \"'we\", 'pay', 'top', 'scale', 'hourly', 'rates', 'based', 'on', 'your', 'credentials,', 'experience', 'and', 'market', 'demand', 'for', 'your', 'skill', \"sets',\", \"'we\", 'can', 'offer', 'other', 'related', 'benefits', 'as', 'needed', 'and', 'customized', 'to', 'your', \"situation',\", \"'we\", 'can', 'work', 'with', 'you', 'to', 'help', 'you', 'achieve', 'your', 'career', 'growth', 'and', \"goals',\", \"'we\", 'offer', 'immediate', 'h1b', 'transfer.', 'immediate', 'green', 'card', 'processing', 'with', 'perm', 'for', 'the', 'right', \"candidates.'\"]\n",
      "\n",
      "\n",
      " tokenized and lemmatized text: \n",
      "['enjoy', 'approv', 'vendor', 'status', 'lead', 'compani', 'pacif', 'northwest', 'continu', 'grow', 'list', 'approv', 'vendor', 'status', 'addit', 'compani', 'ethic', 'integr', 'dedic', 'deliv', 'high', 'result', 'client', 'fair', 'honest', 'busi', 'deal', 'consult', 'client', 'scale', 'hour', 'rat', 'base', 'credenti', 'market', 'demand', 'set', 'relat', 'need', 'custom', 'situat', 'work', 'help', 'achiev', 'growth', 'goal', 'process', 'perm']\n"
     ]
    }
   ],
   "source": [
    "text_sample = df[df.index == 53].values[0][0]\n",
    "\n",
    "print('original text: ')\n",
    "words = []\n",
    "for word in text_sample.split(' '):\n",
    "    words.append(word)\n",
    "print(words)\n",
    "print('\\n\\n tokenized and lemmatized text: ')\n",
    "print(preprocess(text_sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Apply cleaning functions to job_description**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                  [develop, java, web]\n",
       "1     [passion, technolog, learn, natur, curios, lov...\n",
       "2     [enjoy, approv, vendor, status, lead, compani,...\n",
       "3     [enjoy, approv, vendor, status, lead, compani,...\n",
       "4     [sme, linux, oper, strong, virtual, knowledg, ...\n",
       "5     [evalu, extract, transform, data, analyt, purp...\n",
       "6     [techno, function, cpi, technic, expertis, int...\n",
       "7                            [mainten, develop, legaci]\n",
       "8     [enjoy, approv, vendor, status, lead, compani,...\n",
       "10    [enjoy, approv, vendor, status, lead, compani,...\n",
       "Name: job_description, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#apply function and display first 5 rows\n",
    "processed_text = df['job_description'].map(preprocess)\n",
    "processed_text[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I'll use bag of words to extract features from text for use in modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = gensim.corpora.Dictionary(processed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24557"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the length before I filter out the extremes\n",
    "len(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary.filter_extremes(no_below=25, no_above=0.5, keep_n=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3753"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check length after filtering out extremes\n",
    "len(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bow2doc: counts the number of occurrences of each distinct word, \n",
    "#converts the word to its integer word id and returns the result as a sparse vector\n",
    "\n",
    "bow2doc_corpus = [dictionary.doc2bow(text) for text in processed_text]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find optimal number of topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_list, coherence_values = compute_coherence_values(dictionary=dictionary, corpus=bow2doc_corpus,\n",
    " #                                                       texts=processed_text, start=5, limit=40, step=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import matplotlib.pyplot as plt\n",
    "#limit=40; start=5; step=5;\n",
    "#x = range(start, limit, step)\n",
    "#plt.plot(x, coherence_values)\n",
    "#plt.xlabel(\"Number of Topics\")\n",
    "#plt.ylabel(\"Coherence score\")\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA model with Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.LdaMulticore(bow2doc_corpus, \n",
    "                                       num_topics=10, \n",
    "                                       id2word=dictionary, \n",
    "                                       passes=50, \n",
    "                                       workers=4,\n",
    "                                      chunksize=750)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.035*\"status\" + 0.025*\"receiv\" + 0.024*\"protect\" + 0.022*\"origin\" + 0.022*\"success\" + 0.020*\"engin\" + 0.020*\"qualifi\" + 0.019*\"regard\" + 0.016*\"group\" + 0.015*\"factor\"\n",
      "Topic: 1 \n",
      "Words: 0.114*\"data\" + 0.051*\"secur\" + 0.016*\"model\" + 0.015*\"system\" + 0.015*\"inform\" + 0.014*\"architect\" + 0.013*\"analyt\" + 0.013*\"analyst\" + 0.011*\"architectur\" + 0.010*\"analysi\"\n",
      "Topic: 2 \n",
      "Words: 0.013*\"client\" + 0.010*\"solut\" + 0.010*\"help\" + 0.009*\"compani\" + 0.008*\"consult\" + 0.008*\"industri\" + 0.008*\"learn\" + 0.008*\"profession\" + 0.007*\"build\" + 0.007*\"peopl\"\n",
      "Topic: 3 \n",
      "Words: 0.033*\"network\" + 0.020*\"system\" + 0.014*\"technic\" + 0.013*\"oper\" + 0.012*\"environ\" + 0.011*\"softwar\" + 0.011*\"hardwar\" + 0.011*\"troubleshoot\" + 0.011*\"window\" + 0.011*\"issu\"\n",
      "Topic: 4 \n",
      "Words: 0.033*\"market\" + 0.021*\"digit\" + 0.018*\"product\" + 0.017*\"creativ\" + 0.014*\"content\" + 0.012*\"web\" + 0.010*\"user\" + 0.010*\"creat\" + 0.009*\"media\" + 0.009*\"campaign\"\n",
      "Topic: 5 \n",
      "Words: 0.024*\"sql\" + 0.022*\"databas\" + 0.013*\"integr\" + 0.012*\"configur\" + 0.012*\"implement\" + 0.012*\"server\" + 0.011*\"report\" + 0.011*\"function\" + 0.010*\"data\" + 0.009*\"strong\"\n",
      "Topic: 6 \n",
      "Words: 0.052*\"project\" + 0.015*\"abil\" + 0.013*\"plan\" + 0.012*\"process\" + 0.012*\"lead\" + 0.011*\"technic\" + 0.009*\"ensur\" + 0.009*\"solut\" + 0.008*\"strong\" + 0.008*\"implement\"\n",
      "Topic: 7 \n",
      "Words: 0.021*\"softwar\" + 0.020*\"java\" + 0.019*\"web\" + 0.016*\"engin\" + 0.012*\"cloud\" + 0.012*\"code\" + 0.012*\"framework\" + 0.011*\"build\" + 0.011*\"net\" + 0.011*\"api\"\n",
      "Topic: 8 \n",
      "Words: 0.011*\"engin\" + 0.010*\"perform\" + 0.010*\"abil\" + 0.010*\"provid\" + 0.010*\"inform\" + 0.009*\"oper\" + 0.009*\"system\" + 0.008*\"program\" + 0.008*\"process\" + 0.008*\"relat\"\n",
      "Topic: 9 \n",
      "Words: 0.052*\"test\" + 0.022*\"requir\" + 0.021*\"product\" + 0.020*\"softwar\" + 0.017*\"technic\" + 0.015*\"document\" + 0.015*\"user\" + 0.015*\"process\" + 0.012*\"system\" + 0.012*\"function\"\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pickled LDA model results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle.dump(lda_model, open('pickled_models/lda_model.pkl', 'wb'))\n",
    "pickled_lda = pickle.load(open('pickled_models/lda_model.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, topic in pickled_lda.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LDA model evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Coherence Score using c_v\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=processed_text, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Coherence Score using UMass\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=processed_text, dictionary=dictionary, coherence=\"u_mass\")\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pyLDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##visualize the topics in order to better label \n",
    "%matplotlib inline\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "vis = pyLDAvis.gensim.prepare(topic_model=lda_model, corpus=bow2doc_corpus, dictionary=dictionary)\n",
    "pyLDAvis.enable_notebook()\n",
    "pyLDAvis.display(vis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show topics and descriptions\n",
    "df_topic_sents_keywords = show_topics_sentences(ldamodel=pickled_lda, corpus=bow2doc_corpus, texts=df['job_description'])\n",
    "\n",
    "\n",
    "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
    "df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dominant_topic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create df for topic scores for each jobtitle**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_vecs = []\n",
    "for i in range(len(bow2doc_corpus)):\n",
    "    top_topics = pickled_lda.get_document_topics(bow2doc_corpus[i], minimum_probability=0.0)\n",
    "    #i in range(amount of topics)\n",
    "    topic_vec = [top_topics[i][1] for i in range(9)]\n",
    "    topic_vecs.append(topic_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topic_vecs = pd.DataFrame(topic_vecs)\n",
    "df_topic_vecs.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#name columns for df\n",
    "\n",
    "col_names=['Computer Network', 'Web Dev', 'Security', 'Analyst', \n",
    "           'Leadership', 'Database Admin', 'Cloud Computing', 'Computer Support', 'Software/App Dev']\n",
    "\n",
    "\n",
    "df_topic_vecs.columns = col_names\n",
    "df_topic_vecs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#next step merge with original df of job titles and job descriptions\n",
    "#pickle the merged df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.merge(df, df_topic_vecs,left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle.dump(df_final, open('pickled_models/df_final.pkl', 'wb'))\n",
    "pickled_df_final = pickle.load(open('pickled_models/df_final.pkl', 'rb'))\n",
    "pickled_df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = pickled_df_final.drop(['job_description', 'job_title'], axis=1)\n",
    "jobs = pickled_df_final['job_title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nearest_neighbor = NearestNeighbors(n_neighbors=50)\n",
    "nearest_neighbor.fit(topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make Recommendations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "collect_score_and_recommend(nearest_neighbor, jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-36-1f4069552664>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-36-1f4069552664>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    if user_input=='bad'\u001b[0m\n\u001b[0m                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#work in progress\n",
    "def collect_feedback():\n",
    "    \"\"\"Collect user feedback and store it\"\"\"\n",
    "    user_input = input(\"\"\"how'd you like your recommendations? bad, okay, or good\"\"\")\n",
    "    \n",
    "    user_feedback = {}\n",
    "    \n",
    "    if user_input=='bad':\n",
    "    \n",
    "    elif user_input=='okay':\n",
    "    \n",
    "    elif user_input=='good':\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### next-steps\n",
    "#1.clean job-titles!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "#2.recommendations return unique list of top 10\n",
    "#3.seperate functions (textcleaning.py, recommend.py)\n",
    "#4.create function to record feedback and store in mongodb atlas\n",
    "#5.flask, level up some links from your recommendations to jobs\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
